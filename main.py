import os
import json
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import LLMChain

# 1. Load API key
load_dotenv()
google_api_key = os.getenv("GEMINI_API_KEY")

# 2. Kh·ªüi t·∫°o Gemini LLM
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-pro",
    temperature=0.4,
    google_api_key=google_api_key
)

# 3. B·ªô nh·ªõ h·ªôi tho·∫°i
memory = ConversationBufferMemory(memory_key="history", input_key="user_input")

# 4. ƒê·ªãnh nghƒ©a c√°c giai ƒëo·∫°n
stages = {
    "intro": """
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán, chuy√™n gi√∫p c√°c ch·ªß x∆∞·ªüng nh√¥m k√≠nh nh·ªè ·ªü Vi·ªát Nam x√¢y d·ª±ng th∆∞∆°ng hi·ªáu.
H√£y ch√†o kh√°ch h√†ng ng·∫Øn g·ªçn, gi·∫£i th√≠ch l·ª£i √≠ch v√† m·ªùi h·ªç b·∫Øt ƒë·∫ßu.
""",

    "basic_info": """
{history}
H√£y h·ªèi ti·∫øp m·ªôt c√¢u ƒë·ªÉ l·∫•y th√¥ng tin c∆° b·∫£n (t√™n c√¥ng ty, d·ªãch v·ª• ch√≠nh, kh√°ch h√†ng m·ª•c ti√™u).
""",

    "competitive_advantage": """
{history}
H√£y h·ªèi ti·∫øp m·ªôt c√¢u v·ªÅ l·ª£i th·∫ø c·∫°nh tranh c·ªßa c√¥ng ty.
""",

    "core_values": """
{history}
H√£y h·ªèi ti·∫øp v·ªÅ gi√° tr·ªã c·ªët l√µi ho·∫∑c t·∫ßm nh√¨n 3 nƒÉm t·ªõi.
""",

    "style_preferences": """
{history}
H√£y h·ªèi m·ªôt c√¢u v·ªÅ phong c√°ch logo ho·∫∑c m√†u s·∫Øc ch·ªß ƒë·∫°o (t√πy th√¥ng tin n√†o ch∆∞a c√≥).
""",

    "summary": """
{history}
H√£y vi·∫øt m·ªôt ƒëo·∫°n t√≥m t·∫Øt th∆∞∆°ng hi·ªáu d·ª±a tr√™n th√¥ng tin ƒë√£ c√≥:
- T√™n th∆∞∆°ng hi·ªáu
- D·ªãch v·ª• ch√≠nh
- Kh√°ch h√†ng m·ª•c ti√™u
- L·ª£i th·∫ø c·∫°nh tranh
- Gi√° tr·ªã c·ªët l√µi
- T·∫ßm nh√¨n
- Phong c√°ch logo
- M√†u s·∫Øc

K·∫øt th√∫c b·∫±ng c√¢u h·ªèi x√°c nh·∫≠n:
"Anh/ch·ªã th·∫•y ph·∫ßn t√≥m t·∫Øt n√†y ƒë√£ ƒë√∫ng v√† ƒë·ªß ch∆∞a, hay c·∫ßn ch·ªânh s·ª≠a th√™m kh√¥ng ·∫°?"
"""
}

# 5. T·∫°o chain
chains = {
    name: LLMChain(llm=llm, prompt=ChatPromptTemplate.from_template(template), memory=memory, verbose=False)
    for name, template in stages.items()
}

# 6. H√†m tr√≠ch xu·∫•t th√¥ng tin th√†nh JSON
def extract_info(conversation: str):
    extract_prompt = ChatPromptTemplate.from_template("""
B·∫°n l√† m·ªôt h·ªá th·ªëng tr√≠ch xu·∫•t d·ªØ li·ªáu. 
H√£y ph√¢n t√≠ch to√†n b·ªô ƒëo·∫°n h·ªôi tho·∫°i sau v√† xu·∫•t ra JSON ƒë√∫ng c·∫•u tr√∫c:

{{
  "session_id": "t·∫°o id ng·∫´u nhi√™n",
  "dealer_id": "s·ªë ƒëi·ªán tho·∫°i n·∫øu c√≥, n·∫øu kh√¥ng th√¨ ƒë·ªÉ tr·ªëng",
  "brand_name_full": "",
  "location": "",
  "main_services": [],
  "product_portfolio": [],
  "target_customers": [],
  "competitive_advantage": [],
  "core_values": [],
  "slogan": "",
  "future_vision": [],
  "logo_style": [],
  "main_color": [],
  "revenue": ""
}}

Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng gi·∫£i th√≠ch g√¨ th√™m.

ƒêo·∫°n h·ªôi tho·∫°i:
{conversation}
""")

    extract_chain = LLMChain(llm=llm, prompt=extract_prompt, verbose=False)
    response = extract_chain.invoke({"conversation": conversation})
    return json.loads(response["text"])

# 7. H√†m l∆∞u JSON
def save_brand_profile(data, filename="brand_profile.json"):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"‚úÖ H·ªì s∆° th∆∞∆°ng hi·ªáu ƒë√£ l∆∞u v√†o {filename}")

# 8. Ch·∫°y h·ªôi tho·∫°i
def run_chatbot():
    print("ü§ñ Chatbot Gemini - T∆∞ v·∫•n th∆∞∆°ng hi·ªáu\n")
    for stage_name, chain in chains.items():
        print(f"--- {stage_name.upper()} ---")
        user_input = input("B·∫°n: ") if stage_name != "intro" else "Xin ch√†o"
        response = chain.invoke({"user_input": user_input})
        print("Bot:", response["text"])

    # 9. X·ª≠ l√Ω x√°c nh·∫≠n sau summary
    while True:
        user_input = input("B·∫°n: ")
        if any(word in user_input.lower() for word in ["ƒë√∫ng", "ƒë·ªß", "ch√≠nh x√°c", "ok", "oke", "r·ªìi"]):
            print("Bot: Tuy·ªát v·ªùi! R·∫•t vui v√¨ ƒë√£ gi√∫p anh/ch·ªã ƒë·ªãnh h√¨nh th∆∞∆°ng hi·ªáu. üöÄ")

            # L·∫•y to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i
            final_summary = memory.load_memory_variables({})["history"]

            # Tr√≠ch xu·∫•t JSON
            brand_profile = extract_info(final_summary)

            # L∆∞u k·∫øt qu·∫£
            save_brand_profile(brand_profile)

            break
        else:
            fix_prompt = ChatPromptTemplate.from_template("""
{history}
Kh√°ch h√†ng ch∆∞a h√†i l√≤ng v·ªõi b·∫£n t√≥m t·∫Øt, h·ªç mu·ªën ch·ªânh s·ª≠a: "{feedback}".
H√£y vi·∫øt l·∫°i b·∫£n t√≥m t·∫Øt th∆∞∆°ng hi·ªáu ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c h∆°n, sau ƒë√≥ h·ªèi l·∫°i h·ªç x√°c nh·∫≠n.
""")
            fix_chain = LLMChain(llm=llm, prompt=fix_prompt, memory=memory, verbose=False)
            response = fix_chain.invoke({"user_input": user_input, "feedback": user_input})
            print("Bot:", response["text"])

if __name__ == "__main__":
    run_chatbot()
